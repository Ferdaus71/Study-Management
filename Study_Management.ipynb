{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfEAT7GWLyH3",
        "outputId": "38c7b811-2974-4311-9c00-c0b9e06be998"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.12.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai python-dotenv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tz49znJeMLne"
      },
      "source": [
        "# Set Environment Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iC0pL0ILK-it"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2epwTowLdJ5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"MODEL_NAME\"] = \"gpt-4o-mini\"\n",
        "os.environ[\"TEMPERATURE\"] = \"0.3\"\n",
        "os.environ[\"MAX_TOKENS\"] = \"800\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0H0f9qaKLkXn",
        "outputId": "211d6c3a-5849-4e35-e0fe-15460772f7af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "API key loaded: True\n",
            "Model: gpt-4o-mini\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "print(\"API key loaded:\", os.environ.get(\"OPENAI_API_KEY\") is not None)\n",
        "print(\"Model:\", os.environ.get(\"MODEL_NAME\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUCwqVRlL7Q9",
        "outputId": "d7752922-80ed-4e1b-d0cd-8bef8fe29d89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting config.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile config.py\n",
        "import os\n",
        "\n",
        "MODEL_NAME = os.getenv(\"MODEL_NAME\")\n",
        "TEMPERATURE = float(os.getenv(\"TEMPERATURE\"))\n",
        "MAX_TOKENS = int(os.getenv(\"MAX_TOKENS\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deYA3_XyMO06"
      },
      "source": [
        "# Create Provider Layer\n",
        "Base Provider"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgbLXxyiMWkg",
        "outputId": "7da92bd3-ab29-414d-ca1a-ae44342d41fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting base_provider.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile base_provider.py\n",
        "from abc import ABC, abstractmethod\n",
        "\n",
        "class BaseProvider(ABC):\n",
        "\n",
        "    @abstractmethod\n",
        "    def generate(self, prompt: str):\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noEw-WqwMfJS"
      },
      "source": [
        "# OpenAI Provider"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPyEr9GNMiQ4",
        "outputId": "9fe1e000-85c6-40a6-d9f4-bd82c626860f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting openai_provider.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile openai_provider.py\n",
        "from openai import OpenAI\n",
        "from config import MODEL_NAME, TEMPERATURE, MAX_TOKENS\n",
        "\n",
        "class OpenAIProvider:\n",
        "    def __init__(self):\n",
        "        self.client = OpenAI()\n",
        "\n",
        "    def generate(self, prompt: str):\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=MODEL_NAME,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=TEMPERATURE,\n",
        "            max_tokens=MAX_TOKENS\n",
        "        )\n",
        "        return response.choices[0].message.content\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmhE_EQRMrbP"
      },
      "source": [
        "# Prompt Functions\n",
        "Flashcard Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YylucX9_Mvmk",
        "outputId": "45abed84-8455-471a-8292-5f378ff00953"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting flashcard_prompt.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile flashcard_prompt.py\n",
        "def flashcard_prompt(text):\n",
        "    return f\"\"\"\n",
        "Generate flashcards.\n",
        "\n",
        "Return JSON only.\n",
        "\n",
        "Format:\n",
        "[\n",
        "  {{\n",
        "    \"question\": \"...\",\n",
        "    \"answer\": \"...\"\n",
        "  }}\n",
        "]\n",
        "\n",
        "Text:\n",
        "{text}\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0scL25PXM4QU"
      },
      "source": [
        "# Quiz Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HTviVoYM6m6",
        "outputId": "3c28ded6-d890-4f10-948b-5dd80e6ae6e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting quiz_prompt.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile quiz_prompt.py\n",
        "def quiz_prompt(text):\n",
        "    return f\"\"\"\n",
        "Generate MCQ questions.\n",
        "\n",
        "Return JSON only.\n",
        "\n",
        "Format:\n",
        "[\n",
        "  {{\n",
        "    \"question\": \"...\",\n",
        "    \"options\": [\"A\",\"B\",\"C\",\"D\"],\n",
        "    \"correct_answer\": \"A\"\n",
        "  }}\n",
        "]\n",
        "\n",
        "Text:\n",
        "{text}\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wriq0wEaNGSS"
      },
      "source": [
        "# Summary Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IPRohaZNJcl",
        "outputId": "81d3b765-578a-4d90-b20a-af752e279dac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting summary_prompt.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile summary_prompt.py\n",
        "def summary_prompt(text):\n",
        "    return f\"\"\"\n",
        "Summarize the text clearly.\n",
        "\n",
        "Text:\n",
        "{text}\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71U6C33vNTs0"
      },
      "source": [
        "# Evaluation Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKat-L_3NdVL",
        "outputId": "6c3caf7f-d37c-49b1-d3fb-34cca16261ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting evaluation_prompt.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile evaluation_prompt.py\n",
        "def evaluation_prompt(correct, user):\n",
        "    return f\"\"\"\n",
        "Evaluate the answer.\n",
        "\n",
        "Correct:\n",
        "{correct}\n",
        "\n",
        "User:\n",
        "{user}\n",
        "\n",
        "Return JSON:\n",
        "{{\n",
        "  \"score\": 0-100,\n",
        "  \"feedback\": \"short feedback\"\n",
        "}}\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZfGKwQpNz0W"
      },
      "source": [
        "# AI Engines\n",
        "Flashcard Engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGaYUlfKN_mP",
        "outputId": "928c00bd-88a3-4936-d4b5-0eb2512744d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting flashcard_engine.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile flashcard_engine.py\n",
        "from flashcard_prompt import flashcard_prompt\n",
        "\n",
        "class FlashcardEngine:\n",
        "    def __init__(self, provider):\n",
        "        self.provider = provider\n",
        "\n",
        "    def generate(self, text):\n",
        "        return self.provider.generate(flashcard_prompt(text))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UgD69OBOKo8"
      },
      "source": [
        "# Quiz Engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4M1QPIoUOUk4",
        "outputId": "29a612d2-6169-4de5-bb11-5cd506ce908c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting quiz_engine.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile quiz_engine.py\n",
        "from quiz_prompt import quiz_prompt\n",
        "\n",
        "class QuizEngine:\n",
        "    def __init__(self, provider):\n",
        "        self.provider = provider\n",
        "\n",
        "    def generate(self, text):\n",
        "        return self.provider.generate(quiz_prompt(text))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYzBjyxUPFSa"
      },
      "source": [
        "# Summary Engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S__7X2l7PJlD",
        "outputId": "29d18e12-c2e7-40f3-fe4e-40c3b6b1b914"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting summary_engine.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile summary_engine.py\n",
        "from summary_prompt import summary_prompt\n",
        "\n",
        "class SummaryEngine:\n",
        "    def __init__(self, provider):\n",
        "        self.provider = provider\n",
        "\n",
        "    def generate(self, text):\n",
        "        return self.provider.generate(summary_prompt(text))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH5CSfd5PRLM"
      },
      "source": [
        "# Evaluation Engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwlJ78GbPTh8",
        "outputId": "56d2c29e-923f-4205-9a08-2bdddeef5a9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting evaluation_engine.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile evaluation_engine.py\n",
        "from evaluation_prompt import evaluation_prompt\n",
        "\n",
        "class EvaluationEngine:\n",
        "    def __init__(self, provider):\n",
        "        self.provider = provider\n",
        "\n",
        "    def evaluate(self, correct, user):\n",
        "        return self.provider.generate(evaluation_prompt(correct, user))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5R4QdvmPbKJ"
      },
      "source": [
        "# Test Everything MAIN CELL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6VcTFc-Pfup",
        "outputId": "82c2df66-c845-4356-efd3-ce86a06b81a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FLASHCARDS:\n",
            "[\n",
            "  {\n",
            "    \"question\": \"What is machine learning?\",\n",
            "    \"answer\": \"A subset of artificial intelligence that enables systems to learn from data.\"\n",
            "  }\n",
            "]\n",
            "\n",
            "QUIZ:\n",
            "[\n",
            "  {\n",
            "    \"question\": \"What is machine learning a subset of?\",\n",
            "    \"options\": [\"Artificial Intelligence\", \"Data Science\", \"Statistics\", \"Computer Programming\"],\n",
            "    \"correct_answer\": \"A\"\n",
            "  },\n",
            "  {\n",
            "    \"question\": \"What does machine learning enable systems to do?\",\n",
            "    \"options\": [\"Learn from data\", \"Perform calculations\", \"Store information\", \"Execute commands\"],\n",
            "    \"correct_answer\": \"A\"\n",
            "  },\n",
            "  {\n",
            "    \"question\": \"Which of the following best describes machine learning?\",\n",
            "    \"options\": [\"A method for data analysis\", \"A type of programming language\", \"A hardware component\", \"A database management system\"],\n",
            "    \"correct_answer\": \"A\"\n",
            "  },\n",
            "  {\n",
            "    \"question\": \"Is machine learning considered a part of artificial intelligence?\",\n",
            "    \"options\": [\"Yes\", \"No\", \"Only in certain cases\", \"Not applicable\"],\n",
            "    \"correct_answer\": \"A\"\n",
            "  }\n",
            "]\n",
            "\n",
            "SUMMARY:\n",
            "Machine learning is a branch of artificial intelligence that allows systems to learn from data.\n",
            "\n",
            "EVALUATION:\n",
            "{\n",
            "  \"score\": 80,\n",
            "  \"feedback\": \"The statement is partially correct; while ML does learn automatically, it is important to note that it learns from data specifically.\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "from openai_provider import OpenAIProvider\n",
        "from flashcard_engine import FlashcardEngine\n",
        "from quiz_engine import QuizEngine\n",
        "from summary_engine import SummaryEngine\n",
        "from evaluation_engine import EvaluationEngine\n",
        "\n",
        "provider = OpenAIProvider()\n",
        "\n",
        "text = \"\"\"\n",
        "Machine learning is a subset of artificial intelligence\n",
        "that enables systems to learn from data.\n",
        "\"\"\"\n",
        "\n",
        "print(\"FLASHCARDS:\")\n",
        "print(FlashcardEngine(provider).generate(text))\n",
        "\n",
        "print(\"\\nQUIZ:\")\n",
        "print(QuizEngine(provider).generate(text))\n",
        "\n",
        "print(\"\\nSUMMARY:\")\n",
        "print(SummaryEngine(provider).generate(text))\n",
        "\n",
        "print(\"\\nEVALUATION:\")\n",
        "print(EvaluationEngine(provider).evaluate(\n",
        "    \"ML allows systems to learn from data\",\n",
        "    \"ML learns automatically\"\n",
        "))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}